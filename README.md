# week1_week2
Classical ML models and Neural Networks

Week 1: 

1. Linear Regression: House Price Prediction
   - Dataset: [https://www.kaggle.com/datasets/camnugent/california-housing-prices]
   - Course: https://www.youtube.com/watch?v=VmbA0pi2cRQ

2. Polynomial Regression: COVID-19 Case Prediction
   - Dataset: https://www.kaggle.com/datasets/imdevskp/corona-virus-report
   - Course: https://www.youtube.com/watch?v=H8kocPOT5v0&t

3. Logistic Regression: Customer Churn Prediction
   - Dataset: https://www.kaggle.com/datasets/shantanudhakadd/bank-customer-churn-prediction
   - Course: https://www.youtube.com/watch?v=VCJdg7YBbAQ

4. Ridge and Lasso Regression: Gene Expression Analysis
   - Dataset: https://www.kaggle.com/c/gene-expression-prediction/data
   - Course: https://www.youtube.com/watch?v=OH4_Xsk8nfc

Corresponding ipynb with proper names:
HouseSalePredic for task 1
Covid19 for task 2
Customer_churn for task 3
GeneExpression for task 4

Week 2:

Day 1: Decision Trees
- Theory: Complete Decision Trees section in Google ML Course
- Practice: Start with Titanic Survival Prediction
  - Dataset: https://www.kaggle.com/c/titanic
  - Task: Build your first binary classifier using Decision Trees
  - Expected Output: Basic model with accuracy metrics

Day 2: Logistic Regression & Naive Bayes
- Theory: Watch StatQuest videos on Logistic Regression and Naive Bayes
- Practice: Continue with Titanic dataset
  - Compare performance with Day 1's Decision Tree
  - Implement both Logistic Regression and Naive Bayes
  - Expected Output: Comparison of model performances

Day 3: Support Vector Machines (SVM)
- Theory: Complete SVM sections in Google ML Course
- Practice: Iris Flower Classification
  - Dataset: https://www.kaggle.com/uciml/iris
  - Task: Implement multi-class classification using SVM
  - Expected Output: Model evaluation with confusion matrix

Day 4: Random Forest and Ensemble Methods
- Theory: Watch Assembly AI videos on ensemble methods
- Practice: Credit Card Fraud Detection
  - Dataset: https://www.kaggle.com/mlg-ulb/creditcardfraud
  - Task: Implement Random Forest for fraud detection
  - Expected Output: Model with emphasis on handling imbalanced data

Day 5: Neural Networks for Classification
- Theory: Complete Neural Networks section in Google ML Course
- Practice: Improve Credit Card Fraud Detection
  - Implement a simple neural network
  - Compare performance with Day 4's Random Forest
  - Expected Output: Final model comparison and analysis
 
  For week 2 there are 3 ipynb files namely :
  DecisionTrees_Naive Bias , contains Task 1 and 2
  SVMClassification Contains Task 3
  credit_card contains task 4 and task 5
  
